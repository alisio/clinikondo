# üßæ Medifolder - Classificador Automatizado de Documentos M√©dicos

Sistema de linha de comando (CLI) para classifica√ß√£o autom√°tica de documentos m√©dicos (PDFs e imagens) com extra√ß√£o de metadados via LLM, organiza√ß√£o hier√°rquica por paciente e tipo, e renomea√ß√£o padronizada.

## üéØ Funcionalidades

- ‚úÖ **Classifica√ß√£o Autom√°tica**: Organiza documentos por tipo (exames, receitas, laudos, etc.)
- ‚úÖ **Extra√ß√£o via LLM**: Utiliza modelos OpenAI ou compat√≠veis (Ollama) para extrair metadados
- ‚úÖ **Organiza√ß√£o Hier√°rquica**: Cria estrutura `paciente/tipo_documento/arquivo_renomeado.pdf`
- ‚úÖ **Identifica√ß√£o Inteligente**: Reconhece pacientes mesmo com nomes abreviados
- ‚úÖ **Sistema de Retry**: At√© 3 tentativas com timeout configur√°vel (30s)
- ‚úÖ **Logging Estruturado**: Rastreamento completo do processamento
- ‚úÖ **Preserva√ß√£o de Originais**: Arquivos originais s√£o mantidos por padr√£o

## üìã Tipos de Documento Suportados

| Tipo | Pasta Destino | Descri√ß√£o |
|------|---------------|-----------|
| `exame` | `exames` | Resultados, imagens, ultrassom, laborat√≥rio |
| `receita` | `receitas_medicas` | Prescri√ß√µes, medicamentos |
| `vacina` | `vacinas` | Cart√£o de vacina, imuniza√ß√£o |
| `controle` | `controle_de_pressao_e_glicose` | Monitoramento de press√£o/glicose |
| `contato` | `contatos_medicos` | Contatos m√©dicos, telefones, cl√≠nicas |
| `laudo` | `laudos` | Laudos, relat√≥rios, atestados |
| `agenda` | `agendas` | Consultas, agendamentos |
| `documento` | `documentos` | Formul√°rios e documentos gerais |

## üè• Especialidades Reconhecidas

`radiologia`, `laboratorial`, `cardiologia`, `endocrinologia`, `ginecologia`, `clinica_geral`, `dermatologia`, `pediatria`

## ‚öôÔ∏è Configura√ß√£o

### 1. **Instala√ß√£o**

```bash
# Clone o reposit√≥rio
git clone <url-do-repo>
cd medifolder

# Crie e ative ambiente virtual
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Instale depend√™ncias
pip install -e .[dev]
```

### 2. **Configura√ß√£o do LLM**

#### **Op√ß√£o A: OpenAI**
```bash
export OPENAI_API_KEY="sua-chave-openai"
export OPENAI_API_BASE="https://api.openai.com/v1"  # opcional
```

#### **Op√ß√£o B: Ollama (Local)**
```bash
# Instale Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Execute um modelo
ollama run gpt-oss:20b  # ou outro modelo compat√≠vel

# Configure vari√°veis
export OPENAI_API_KEY="mock-key"  # qualquer valor
export OPENAI_API_BASE="http://localhost:11434/v1"
```

### 3. **Estrutura de Pastas**

```bash
# Crie as pastas necess√°rias
mkdir -p ~/medifolder/entrada
mkdir -p ~/medifolder/saida

# Coloque documentos m√©dicos para processar
cp seus_documentos.pdf ~/medifolder/entrada/
```

## üöÄ Como Usar

### **Comando B√°sico**
```bash
python -m medifolder \
  --input ~/medifolder/entrada \
  --output ~/medifolder/saida \
  --model gpt-4 \
  --log-level info
```

### **Com Ollama Local**
```bash
PYTHONPATH=/path/to/medifolder/src python -m medifolder \
  --input ~/medifolder/entrada \
  --output ~/medifolder/saida \
  --model gpt-oss:20b \
  --api-base http://localhost:11434/v1 \
  --api-key mock-key \
  --temperature 0.3 \
  --max-tokens 1024 \
  --log-level info
```

### **Modo Teste (Dry-run)**
```bash
python -m medifolder \
  --input ~/medifolder/entrada \
  --output ~/medifolder/saida \
  --model gpt-4 \
  --dry-run  # N√£o move arquivos, apenas simula
```

## üìä Par√¢metros Dispon√≠veis

| Par√¢metro | Tipo | Padr√£o | Descri√ß√£o |
|-----------|------|--------|-----------|
| `--input` | path | - | **Obrigat√≥rio**: Pasta com documentos para processar |
| `--output` | path | - | **Obrigat√≥rio**: Pasta de destino organizada |
| `--model` | string | `gpt-4` | Modelo LLM a usar |
| `--api-base` | url | OpenAI | Endpoint da API (para Ollama: `http://localhost:11434/v1`) |
| `--api-key` | string | - | Chave da API (para Ollama: qualquer valor) |
| `--temperature` | float | `0.2` | Criatividade do modelo (0.0-1.0) |
| `--max-tokens` | int | `512` | Tokens m√°ximos na resposta |
| `--log-level` | string | `info` | N√≠vel de log: `debug`, `info`, `warning`, `error` |
| `--dry-run` | bool | `false` | Simula sem mover arquivos |
| `--mover` | bool | `false` | Move (deleta originais) em vez de copiar |

## üìÅ Estrutura de Sa√≠da

```
~/medifolder/saida/
‚îú‚îÄ‚îÄ antonio_alisio_de_menezes_cordeiro/
‚îÇ   ‚îú‚îÄ‚îÄ exames/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2024-03-15-antonio_alisio_de_menezes_cordeiro-exame-laboratorial-hemograma-completo.pdf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 2024-02-20-antonio_alisio_de_menezes_cordeiro-exame-cardiologia-eletrocardiograma.pdf
‚îÇ   ‚îú‚îÄ‚îÄ receitas_medicas/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 2024-03-10-antonio_alisio_de_menezes_cordeiro-receita-cardiologia-captopril-uso-continuo.pdf
‚îÇ   ‚îî‚îÄ‚îÄ laudos/
‚îÇ       ‚îî‚îÄ‚îÄ 2024-03-01-antonio_alisio_de_menezes_cordeiro-laudo-radiologia-radiografia-torax.pdf
‚îî‚îÄ‚îÄ maria_silva_santos/
    ‚îî‚îÄ‚îÄ vacinas/
        ‚îî‚îÄ‚îÄ 2024-01-15-maria_silva_santos-vacina-pediatria-covid-terceira-dose.pdf
```

## üîß Troubleshooting

### **Problema: "ImportError: No module named 'openai'"**
```bash
pip install openai
```

### **Problema: "OPENAI_API_KEY n√£o configurada"**
```bash
export OPENAI_API_KEY="sua-chave-aqui"
```

### **Problema: "Connection refused" com Ollama**
```bash
# Verifique se Ollama est√° rodando
ollama ps

# Inicie se necess√°rio
ollama serve &
ollama run gpt-oss:20b
```

### **Problema: C√≥digo n√£o atualiza ap√≥s edi√ß√µes**
```bash
# Use PYTHONPATH para for√ßar vers√£o local
PYTHONPATH=/path/to/medifolder/src python -m medifolder [argumentos]
```

## üìù Exemplos de Uso

### **1. Processamento B√°sico**
```bash
python -m medifolder --input ./docs --output ./organized --model gpt-4
```

### **2. Com Configura√ß√µes Personalizadas**
```bash
python -m medifolder \
  --input ./medical_docs \
  --output ./sorted_docs \
  --model gpt-3.5-turbo \
  --temperature 0.1 \
  --max-tokens 256 \
  --log-level debug
```

### **3. Teste com Ollama**
```bash
export PYTHONPATH=/Users/seu-usuario/dev/medifolder/src
python -m medifolder \
  --input ~/documentos_medicos \
  --output ~/documentos_organizados \
  --model llama3:8b \
  --api-base http://localhost:11434/v1 \
  --api-key qualquer-coisa \
  --dry-run
```

## üìñ Logs e Monitoramento

O sistema gera logs estruturados conforme SRS:

```json
{
  "arquivo": "exame_sangue.pdf",
  "status": "sucesso", 
  "confianca_extracao": 0.95,
  "metodo_extracao": "llm",
  "paciente_identificado": "antonio_cordeiro",
  "tipo_documento": "exame",
  "especialidade": "laboratorial",
  "duracao_total_ms": 3214,
  "timestamp": "2024-03-15T14:30:22Z"
}
```

## üéØ Crit√©rios de Qualidade

- ‚úÖ **‚â• 90%** de documentos corretamente classificados
- ‚úÖ **‚â• 95%** de acur√°cia na identifica√ß√£o de pacientes  
- ‚úÖ **‚â• 95%** das requisi√ß√µes LLM conclu√≠das em 30s
- ‚úÖ **100%** dos originais preservados (modo padr√£o)
- ‚úÖ **100%** de detec√ß√£o de duplicatas por hash SHA-256

## üß™ Testes

```bash
# Execute todos os testes
pytest

# Testes com cobertura
pytest --cov=medifolder

# Teste espec√≠fico
pytest tests/test_processing.py -v
```
